{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BaPoDGlGW4JJ",
        "5G6RH5I9pWQi",
        "YCut_zKcyvGt"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedrocassalpacheco/AWID-Intrusion-Detection/blob/master/RAG_with_Semantic_Kernal_using_Astra_DB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RAG with Semantic Kernal using Astra DB**"
      ],
      "metadata": {
        "id": "zOy6oqXF7l3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This an example of building a Retrieval Augmented Generation (RAG) application efficiently by configuring Semantic Kernal using Astra DB MemoryStore. You just need to folllow and execute those steps below.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a9WjI3itCpCS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install libraries**\n"
      ],
      "metadata": {
        "id": "_2bHZGUWVSqE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJEVPMLq1944",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f54ad942-42fc-4108-f517-e6ab9dedd527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting semantic-kernel\n",
            "  Downloading semantic_kernel-0.9.3b1-py3-none-any.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.4/264.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0,>=3.8 in /usr/local/lib/python3.10/dist-packages (from semantic-kernel) (3.9.3)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from semantic-kernel) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.50.0 in /usr/local/lib/python3.10/dist-packages (from semantic-kernel) (1.62.1)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from semantic-kernel) (3.1.3)\n",
            "Collecting motor<4.0.0,>=3.3.2 (from semantic-kernel)\n",
            "  Downloading motor-3.3.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from semantic-kernel) (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.10/dist-packages (from semantic-kernel) (1.25.2)\n",
            "Collecting openai>=1.0 (from semantic-kernel)\n",
            "  Downloading openai-1.14.2-py3-none-any.whl (262 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.4/262.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openapi_core<0.20,>=0.18 (from semantic-kernel)\n",
            "  Downloading openapi_core-0.19.0-py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.7/100.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prance<24.0.0.0,>=23.6.21.0 (from semantic-kernel)\n",
            "  Downloading prance-23.6.21.0-py3-none-any.whl (36 kB)\n",
            "Collecting pybars4<0.10.0,>=0.9.13 (from semantic-kernel)\n",
            "  Downloading pybars4-0.9.13.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from semantic-kernel) (2.6.4)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.1 (from semantic-kernel)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: regex<2024.0.0,>=2023.6.3 in /usr/local/lib/python3.10/dist-packages (from semantic-kernel) (2023.12.25)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from semantic-kernel) (1.11.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->semantic-kernel) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->semantic-kernel) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->semantic-kernel) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->semantic-kernel) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->semantic-kernel) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->semantic-kernel) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.3->semantic-kernel) (2.1.5)\n",
            "Collecting pymongo<5,>=4.5 (from motor<4.0.0,>=3.3.2->semantic-kernel)\n",
            "  Downloading pymongo-4.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.2/677.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0->semantic-kernel) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.0->semantic-kernel) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=1.0->semantic-kernel)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.0->semantic-kernel) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0->semantic-kernel) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0->semantic-kernel) (4.10.0)\n",
            "Collecting isodate (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema<5.0.0,>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (4.19.2)\n",
            "Collecting jsonschema-path<0.4.0,>=0.3.1 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading jsonschema_path-0.3.2-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (10.1.0)\n",
            "Collecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading openapi_schema_validator-0.6.2-py3-none-any.whl (8.8 kB)\n",
            "Collecting openapi-spec-validator<0.8.0,>=0.7.1 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading openapi_spec_validator-0.7.1-py3-none-any.whl (38 kB)\n",
            "Collecting parse (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading parse-1.20.1-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: werkzeug in /usr/local/lib/python3.10/dist-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (3.0.1)\n",
            "Requirement already satisfied: chardet>=3.0 in /usr/local/lib/python3.10/dist-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel) (5.2.0)\n",
            "Collecting ruamel.yaml>=0.17.10 (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel)\n",
            "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.25 in /usr/local/lib/python3.10/dist-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel) (2.31.0)\n",
            "Requirement already satisfied: six~=1.15 in /usr/local/lib/python3.10/dist-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel) (1.16.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel) (24.0)\n",
            "Collecting PyMeta3>=0.5.1 (from pybars4<0.10.0,>=0.9.13->semantic-kernel)\n",
            "  Downloading PyMeta3-0.5.1.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->semantic-kernel) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->semantic-kernel) (2.16.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.0->semantic-kernel) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.0->semantic-kernel) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.0->semantic-kernel) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.0->semantic-kernel)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0->semantic-kernel)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.18.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (6.0.1)\n",
            "Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading pathable-0.4.3-py3-none-any.whl (9.6 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading referencing-0.31.1-py3-none-any.whl (25 kB)\n",
            "Collecting rfc3339-validator (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting lazy-object-proxy<2.0.0,>=1.7.1 (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading lazy_object_proxy-1.10.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.3/68.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0 (from pymongo<5,>=4.5->motor<4.0.0,>=3.3.2->semantic-kernel)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic-kernel) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic-kernel) (2.0.7)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.10->prance<24.0.0.0,>=23.6.21.0->semantic-kernel)\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pybars4, PyMeta3\n",
            "  Building wheel for pybars4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybars4: filename=pybars4-0.9.13-py3-none-any.whl size=14340 sha256=9dcbba0eeb0078e9e7a5704b8d8c2d2749bc97e5b2c690a3ba18b320911dc366\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/aa/f7/0fca6ca6dabcd593ef782462477b2b5b891f477c407072e30a\n",
            "  Building wheel for PyMeta3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyMeta3: filename=PyMeta3-0.5.1-py3-none-any.whl size=16448 sha256=fdf1d017181178c22072cbfb1675baecb0aac50f278a06a6206bf5330d46a07a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/ef/62/1d388a1576d871760164a1388632b29645c3f907cd009d6cb1\n",
            "Successfully built pybars4 PyMeta3\n",
            "Installing collected packages: PyMeta3, parse, ruamel.yaml.clib, rfc3339-validator, referencing, python-dotenv, pybars4, pathable, lazy-object-proxy, isodate, h11, dnspython, ruamel.yaml, pymongo, jsonschema-path, httpcore, prance, motor, httpx, openapi-schema-validator, openai, openapi-spec-validator, openapi_core, semantic-kernel\n",
            "  Attempting uninstall: referencing\n",
            "    Found existing installation: referencing 0.33.0\n",
            "    Uninstalling referencing-0.33.0:\n",
            "      Successfully uninstalled referencing-0.33.0\n",
            "Successfully installed PyMeta3-0.5.1 dnspython-2.6.1 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 isodate-0.6.1 jsonschema-path-0.3.2 lazy-object-proxy-1.10.0 motor-3.3.2 openai-1.14.2 openapi-schema-validator-0.6.2 openapi-spec-validator-0.7.1 openapi_core-0.19.0 parse-1.20.1 pathable-0.4.3 prance-23.6.21.0 pybars4-0.9.13 pymongo-4.6.2 python-dotenv-1.0.1 referencing-0.31.1 rfc3339-validator-0.1.4 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 semantic-kernel-0.9.3b1\n"
          ]
        }
      ],
      "source": [
        "%pip install semantic-kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Modules**"
      ],
      "metadata": {
        "id": "l3M7fv6yWZLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
        "from semantic_kernel.memory.memory_store_base import MemoryStoreBase\n",
        "import semantic_kernel as sk\n",
        "from semantic_kernel.connectors.ai.open_ai import (\n",
        "    OpenAIChatCompletion,\n",
        "    OpenAITextEmbedding\n",
        ")\n",
        "from semantic_kernel.connectors.memory.astradb import AstraDBMemoryStore\n",
        "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
        "from semantic_kernel.core_plugins.text_memory_plugin import TextMemoryPlugin\n",
        "import semantic_kernel.connectors.ai.open_ai as sk_oai\n",
        "from semantic_kernel.prompt_template.input_variable import InputVariable"
      ],
      "metadata": {
        "id": "V0RON-Xa2AJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load ENV Variables**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BaPoDGlGW4JJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# env vars for astra memory store\n",
        "# ASTRA_DB_TOKEN = os.environ.get(\"ASTRA_DB_TOKEN\")\n",
        "# ASTRA_DB_ID= os.environ.get(\"ASTRA_DB_ID\")\n",
        "# ASTRA_REGION = os.environ.get(\"ASTRA_REGION\")\n",
        "# KEYSPACE = os.environ.get(\"KEYSPACE\")\n",
        "# EMBEDDING_DIMENSION = os.environ.get(\"EMBEDDING_DIMENSION\")\n",
        "# SIMILARITY = os.environ.get(\"SIMILARITY\")\n",
        "# COLLECTION_NAME = os.environ.get(\"COLLECTION_NAME\")\n",
        "\n",
        "\n",
        "# CHAT_COMPLETION_MODEL: str= \"gpt-3.5-turbo\"\n",
        "# TEXT_EMBEDDING_MODEL: str= \"text-embedding-ada-002\"\n",
        "# OPEN_AI_API_KEY: str= \"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\"\n",
        "# env vars for open models\n",
        "CHAT_COMPLETION_MODEL= os.environ.get(\"CHAT_COMPLETION_MODEL\")   # it should be a Model of text generation type like \"text-embedding-ada-002\"\n",
        "TEXT_EMBEDDING_MODEL=os.environ.get(\"TEXT_EMBEDDING_MODEL\")  # it should be a Model of Chat Completion type like \"gpt-3.5-turbo\"\n",
        "OPEN_AI_API_KEY=os.environ.get(\"OPEN_AI_API_KEY\")"
      ],
      "metadata": {
        "id": "5ootJLhk9tsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Initialize Semantic Kernal and Add Chat & Embedding services**"
      ],
      "metadata": {
        "id": "5G6RH5I9pWQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize semantic kernal\n",
        "kernel = sk.Kernel()\n",
        "\n",
        "#Add OpenAI chat_completion service\n",
        "kernel.add_service(\n",
        "    OpenAIChatCompletion(\n",
        "        service_id=\"chat_completion\",\n",
        "        ai_model_id=CHAT_COMPLETION_MODEL,\n",
        "        api_key=OPEN_AI_API_KEY\n",
        "    )\n",
        ")\n",
        "print(\"Added OpenAI Chat Service\")\n",
        "\n",
        "#Add OpenAI text_embedding service\n",
        "kernel.add_service(\n",
        "    OpenAITextEmbedding(\n",
        "        service_id=\"text_embedding\",\n",
        "        ai_model_id=TEXT_EMBEDDING_MODEL,\n",
        "        api_key=OPEN_AI_API_KEY,\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"Added OpenAI Embedding Service\")"
      ],
      "metadata": {
        "id": "fku-UzEb9vPp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "947a55c8-0fdc-486e-e57c-3e923be2a824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for __init__\nai_model_id\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.6/v/string_type",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ae992ec3a554>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Add OpenAI chat_completion service\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m kernel.add_service(\n\u001b[0;32m----> 6\u001b[0;31m     OpenAIChatCompletion(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mservice_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"chat_completion\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mai_model_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHAT_COMPLETION_MODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_chat_completion.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ai_model_id, api_key, org_id, service_id, default_headers, async_client)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0masync_client\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAsyncOpenAI\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mAn\u001b[0m \u001b[0mexisting\u001b[0m \u001b[0mclient\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \"\"\"\n\u001b[0;32m--> 112\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mai_model_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mai_model_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/validate_call_decorator.py\u001b[0m in \u001b[0;36mwrapper_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalidate_call_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mwrapper_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_validate_call.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydantic_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgsKwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__return_pydantic_validator__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__return_pydantic_validator__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for __init__\nai_model_id\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.6/v/string_type"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Register Astra DB memory in Semantic kernal**"
      ],
      "metadata": {
        "id": "cVigdyHpxGbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create Astra memory store\n",
        "store = AstraDBMemoryStore(ASTRA_DB_TOKEN, ASTRA_DB_ID, ASTRA_REGION, KEYSPACE, EMBEDDING_DIMENSION, SIMILARITY)\n",
        "#register Astra memory in Semantic Kernal Memory\n",
        "memory = SemanticTextMemory(storage=store, embeddings_generator=kernel.get_service(\"text_embedding\"))\n",
        "kernel.import_plugin_from_object(TextMemoryPlugin(memory), \"TextMemoryPluginACDB\")"
      ],
      "metadata": {
        "id": "9U_IJnGpHtPK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "505e69e3-4cea-487d-f418-b5878748bf7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'>' not supported between instances of 'NoneType' and 'int'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1fcbe588f46f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create Astra memory store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAstraDBMemoryStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mASTRA_DB_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mASTRA_DB_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mASTRA_REGION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKEYSPACE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_DIMENSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIMILARITY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#register Astra memory in Semantic Kernal Memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSemanticTextMemory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_generator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_service\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_embedding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_plugin_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTextMemoryPlugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TextMemoryPluginACDB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/semantic_kernel/connectors/memory/astradb/astradb_memory_store.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, astra_application_token, astra_id, astra_region, keyspace_name, embedding_dim, similarity, session)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding_dim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mMAX_DIMENSIONALITY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             raise ServiceInitializationError(\n\u001b[1;32m     59\u001b[0m                 \u001b[0;34mf\"Dimensionality of {self._embedding_dim} exceeds \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'int'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chat functionality from OpenAI chat model**"
      ],
      "metadata": {
        "id": "Mr3P2IF2xjUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add a dumy prompt\n",
        "prompt = \"\"\"\n",
        "    You are an AI chatbot just answer with precise and short description using provided context\n",
        "    provided context: {{$db_content}}\n",
        "    Chatbot:\"\"\"\n",
        "\n",
        "# configure chat settings for chat_completion model\n",
        "execution_settings = sk_oai.OpenAITextPromptExecutionSettings(\n",
        "   service_id=\"chat_completion\",\n",
        "    ai_model_id=CHAT_COMPLETION_MODEL,\n",
        "    max_tokens=500,\n",
        "    temperature=0.0,\n",
        "    top_p=0.5\n",
        ")\n",
        "\n",
        "chat_prompt_template_config = sk.PromptTemplateConfig(\n",
        "    template=prompt,\n",
        "    name=\"grounded_response\",\n",
        "    template_format=\"semantic-kernel\",\n",
        "    input_variables=[\n",
        "        InputVariable(name=\"db_content\", description=\"database content\", is_required=True),\n",
        "        InputVariable(name=\"users_query\", description=\"user input\", is_required=True),\n",
        "    ],\n",
        "    execution_settings=execution_settings\n",
        ")\n",
        "\n",
        "chat = kernel.create_function_from_prompt(\n",
        " prompt=prompt,\n",
        " function_name= \"ChatGPTFunc2\", plugin_name=\"chatGPTPlugin2\", prompt_template_config=chat_prompt_template_config\n",
        ")\n"
      ],
      "metadata": {
        "id": "c9liDhh3H-QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Function to Load data from file path & Upsert in Astra as content**\n"
      ],
      "metadata": {
        "id": "YCut_zKcyvGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upsert data using\n",
        "\n",
        "async def upsert_data(memory: SemanticTextMemory, store: MemoryStoreBase, data_file_path: str) -> None:\n",
        "\n",
        "    with open(file= data_file_path, mode=\"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "        n = 0\n",
        "        for item in data:\n",
        "            n += 1\n",
        "            try:\n",
        "                data_already_created = bool(\n",
        "                    await store.get(\n",
        "                        COLLECTION_NAME, item[\"id\"], with_embedding=True\n",
        "                    )\n",
        "                )\n",
        "            except Exception:\n",
        "                data_already_created = False\n",
        "            # if the record doesn't exist, we generate embeddings and save it to the database\n",
        "            if not data_already_created:\n",
        "                await memory.save_information(\n",
        "                    collection=COLLECTION_NAME,\n",
        "                    id=item[\"id\"],\n",
        "                    # it generate embedding from text field\n",
        "                    text=item[\"content\"],\n",
        "                    description=item[\"title\"],\n",
        "                )\n",
        "            else:\n",
        "                print(\"Skipping item already exits:\", n, \"/\", len(data), end=\"\\r\")\n"
      ],
      "metadata": {
        "id": "symb1vAey3_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Execute RAG flow**"
      ],
      "metadata": {
        "id": "ukCPNN24yUBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upsert data inside ASTRA DB for context\n",
        "await upsert_data(memory, store, \"/path/to/data.json\")\n",
        "\n",
        "# query whatever you want and it respond with as per given context\n",
        "users_query = \"users input query\"\n",
        "\n",
        "result = await memory.search(COLLECTION_NAME, users_query);\n",
        "completions_result = await kernel.invoke(chat, sk.KernelArguments(users_query=users_query, db_content=result[0].text))\n",
        "print(completions_result)\n"
      ],
      "metadata": {
        "id": "En_ZOyTfICKi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}